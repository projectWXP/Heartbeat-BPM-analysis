from scipy.io import wavfile
from scipy import signal
import numpy as np
import matplotlib.pyplot as plt
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import sys
import warnings

# Load audio data
import os

# Initialize wav_files
wav_files = []

if len(sys.argv) > 1:  # Check if a file path was passed as an argument
    wav_file_path = sys.argv[1]  # Use the file path from the argument
else:
    wav_files = [f for f in os.listdir("input_data") if f.endswith('.wav')]
    if not wav_files:
        raise FileNotFoundError("No .wav files found in the 'input_data' folder")
    wav_file_path = os.path.join("input_data", wav_files[0])

# Extract the file name without the extension
file_name = os.path.splitext(os.path.basename(wav_file_path))[0]

#ignore warning generated by the wavfile.read function. can most likely ignore
with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    sample_rate, audio_data = wavfile.read(wav_file_path)

# Convert to mono if it's stereo================================================================================================================
if len(audio_data.shape) == 2:
    audio_data_mono = np.mean(audio_data, axis=1).astype(np.int16)
else:
    audio_data_mono = audio_data

def downsample_audio(audio_data, downsample_factor):
    # Reshape the audio data so that it can be downsampled
    length = len(audio_data)
    new_length = length // downsample_factor
    audio_data_resampled = audio_data[:new_length * downsample_factor].reshape((new_length, downsample_factor))
    
    # Take the mean along the new axis to downsample
    audio_data_downsampled = audio_data_resampled.mean(axis=1)
    
    return audio_data_downsampled

# downsample audio
downsample_factor = 10 #can adjust
audio_data_mono = downsample_audio(audio_data_mono, downsample_factor)
sample_rate = sample_rate // downsample_factor

# Global normalization
max_amplitude = np.max(np.abs(audio_data_mono))
audio_data_normalized = audio_data_mono / max_amplitude

# Calculate rolling average and standard deviation
window_time = 0.5  # can adjust, window of time to  calculate average and std deviation, in seconds, default .5
window_size = int(window_time * sample_rate)
rolling_avg = signal.fftconvolve(np.abs(audio_data_mono), np.ones(window_size) / window_size, mode='same')
rolling_std = signal.fftconvolve(np.abs(audio_data_mono - rolling_avg), np.ones(window_size) / window_size, mode='same') ** 0.5

# Perform local normalization
alpha = .2  # can adjust, higher for weaker normalization, default .2
audio_data_normalized = (audio_data_mono - rolling_avg) / (rolling_std + alpha)

# Length of the audio in seconds
audio_length_seconds = len(audio_data_normalized) / sample_rate

# Create an array of time windows for calculating BPM
window_length = 4 # can adjust, higher = smoother graph, default 5
time_windows = np.arange(0, audio_length_seconds - window_length, 1)

# Initialize variables
s1_s2_Divider = 1 #(1) if s1 or s2 is signifigantly louder, (2) if both beats are detected
threshold_multiplier = 2.3 # can adjust, higher for higher threshold, default 2 to 3
cooldown_multiplier = 0.7 # can adjust, xx% of the time between each beat, default .7
max_bpm = 260 # can adjust, clamps detection range
min_bpm = 40 # can adjust
smart_peaks = []#detected peaks
current_bpm = 120  # Initialize with a reasonable default
dynamic_threshold = np.mean(np.abs(audio_data_normalized)) * threshold_multiplier

# Initialize next_peak_allowed_time array
next_peak_allowed_time = np.zeros(len(audio_data_normalized))

# Initialize a variable to keep track of whether the BPM is valid and smoothed BPM
smoothed_bpm = None
smoothing_factor = 0.8  # can adjust, higher = the average more sensitive, default .7 to .8

# Loop through the audio data to perform smart peak detection
for i in range(len(audio_data_normalized) - 1):
    valid_bpm = True
    current_time = i / sample_rate
    current_amplitude = audio_data_normalized[i]
  
    if current_time >= next_peak_allowed_time[i]:
        if current_amplitude > dynamic_threshold: #maybe consider abs(current_amplitude) for both sides of the waveform
            # Detected a peak
            smart_peaks.append(i)
            
            # Update current_bpm based on last two peaks
            if len(smart_peaks) >= 2:
                time_between_peaks = (smart_peaks[-1] - smart_peaks[-2]) / sample_rate
                current_bpm = 60 / time_between_peaks
                if current_bpm < min_bpm or current_bpm > max_bpm:
                    # Invalid BPM, set a flag
                    valid_bpm = False
                # Apply smoothing
                if smoothed_bpm is None:
                    smoothed_bpm = current_bpm
                else:
                    smoothed_bpm = (smoothing_factor * smoothed_bpm) + ((1 - smoothing_factor) * current_bpm)
            # Update next_peak_allowed_time to enforce cooldown
            if valid_bpm and smoothed_bpm is not None:
                cooldown_samples = int(sample_rate * (60 / smoothed_bpm) * cooldown_multiplier)
            else:
                # Set a default cooldown time if BPM is not valid
                default_cooldown_time = 0.4  # in seconds, can adjust, default .4 to .45
                cooldown_samples = int(sample_rate * default_cooldown_time)
                
            next_allowed_time = current_time + (cooldown_samples / sample_rate)
            next_peak_allowed_time[i:i+cooldown_samples] = next_allowed_time

# Convert to a NumPy array for easier manipulation
smart_peaks = np.array(smart_peaks)
smart_peaks = np.unique(smart_peaks)

# Exit Script if no peaks detected
if smart_peaks.size == 0:
    print("No peaks detected")
    sys.exit()

# Calculate time instances for these smartly detected peaks
smart_peak_times = smart_peaks / sample_rate

# Initialize array to store smart BPM values
smart_bpm_values = []

# Calculate BPM for each time window using smart peaks
for start_time in time_windows:
    end_time = start_time + window_length
    peaks_in_window = smart_peak_times[(smart_peak_times >= start_time) & (smart_peak_times < end_time)]
    if len(peaks_in_window) >= 2:
        avg_bpm = (60 * len(peaks_in_window) / (peaks_in_window[-1] - peaks_in_window[0])) / s1_s2_Divider
        smart_bpm_values.append(avg_bpm)
    else:
        smart_bpm_values.append(np.nan)

# Visualization===========================================================================================================================
total_duration = len(audio_data_mono) / sample_rate
max_duration = 1800  # 30 minutes in seconds
segment_start = 0 # Start time in seconds, can adjust
segment_end = min(total_duration, max_duration)
segment_start_sample = int(segment_start * sample_rate)
segment_end_sample = int(segment_end * sample_rate)

# Create the figure
fig = go.Figure()

# Downsample the audio data
high_res_downsample_factor = downsample_factor * 1# integer, can adjust
low_res_downsample_factor = downsample_factor * 5# integer, can adjust
low_res_audio_data_downsampled = audio_data_mono[segment_start_sample:segment_end_sample:low_res_downsample_factor]
time_low_res_downsampled = np.arange(segment_start_sample, segment_end_sample, low_res_downsample_factor) / sample_rate
high_res_audio_data_downsampled = audio_data_mono[segment_start_sample:segment_end_sample:high_res_downsample_factor]
time_high_res_downsampled = np.arange(segment_start_sample, segment_end_sample, high_res_downsample_factor) / sample_rate

# Add the high-resolution waveform trace
fig.add_trace(go.Scatter(
    x=time_high_res_downsampled,
    y=high_res_audio_data_downsampled,
    mode='lines',
    name='Waveform (High Res)',
    line=dict(color='#e3745d'),  # Red
    xaxis='x1',
    visible='legendonly'
))

# Add the downsampled waveform trace
fig.add_trace(go.Scatter(
    x=time_low_res_downsampled,
    y=low_res_audio_data_downsampled,
    mode='lines',
    name='Waveform (Low Res)',
    line=dict(color='#47a5c4'),  # Blue
    xaxis='x1',
    visible=True
))

# Add the peaks trace
segment_smart_peaks = smart_peaks[(smart_peaks >= segment_start_sample) & (smart_peaks < segment_end_sample)]
fig.add_trace(go.Scatter(
    x=segment_smart_peaks / sample_rate,
    y=audio_data_mono[segment_smart_peaks],
    mode='markers',
    marker=dict(size=5, color='#4a4a4a'),
    name='Peaks',
    xaxis='x1',
    visible=True
))

# Calculate the labels and positions for the new x-axis
axis_interval = 10  # can adjust graph axis display, in seconds
xticks_positions = np.arange(segment_start, segment_end, axis_interval)
xticks_labels = [f"{int(tick//60):02d}:{int(tick%60):02d}" for tick in xticks_positions]

# Layout customization
fig.update_layout(
    updatemenus=[
        dict(
            type="buttons",
            x=1.05,
            y=0,
            buttons=[
                dict(label="Low Res", method="update", args=[{"visible": [False, True, True]}]),
                dict(label="High Res", method="update", args=[{"visible": [True, False, True]}]),
            ],
        )
    ],
    title=f"Detected Peaks in Segment - File: {file_name}",
    xaxis=dict(
        domain=[0, 1],
        rangeslider=dict(
            visible=True
        ),
        type="linear",
        title="Time (s)"
    ),
    yaxis=dict(
        title="Amplitude"
    ),
    dragmode='pan'
)

# Get the maximum amplitude in your segment for positioning the annotations
max_amplitude = np.max(audio_data_mono[segment_start_sample:segment_end_sample])

# Adding annotations for minute:second format
for tick in xticks_positions:
    fig.add_annotation(
        x=tick,
        y=max_amplitude,
        xref="x",
        yref="y",
        text=f"{int(tick//60):02d}:{int(tick%60):02d}",
        showarrow=False,
        ax=0,
        ay=40
    )

# Show the figure
fig.show(config={'scrollZoom': True})

# plotly smart BPM over time=====================================================================================================
# Find the index of the maximum BPM value
max_bpm_index = np.argmax(smart_bpm_values)
max_bpm_time = time_windows[max_bpm_index]
max_bpm = smart_bpm_values[max_bpm_index]

# Find the index of the minimum BPM value
min_bpm_index = np.argmin(smart_bpm_values)
min_bpm_time = time_windows[min_bpm_index]
min_bpm = smart_bpm_values[min_bpm_index]

avg_bpm = np.mean(smart_bpm_values)

# Shift the x-axis since window_length time needs to pass before data is valid
shifted_time_windows = np.array(time_windows) + window_length - 4 # further adjust

# Create plotly figure 
fig = go.Figure()

# Add BPM trace
fig.add_trace(go.Scatter(
    x=shifted_time_windows, 
    y=smart_bpm_values,
    mode='lines+markers',
    name='BPM'
))

# Add shapes for horizontal lines
fig.add_shape(dict(
    type="line", 
    y0=60, y1=60,
    x0=0, x1=max(shifted_time_windows),
    line=dict(color='#8ede73', width=2)
))

# Add annotations
fig.add_annotation(
    x=max_bpm_time,
    y=max_bpm,
    text=f"{max_bpm:.1f}",
    showarrow=False
)

# Layout
fig.update_layout(
  title=f"BPM Over Time - {file_name}",
  xaxis=dict(
    title='Time (sec)'  
  ),
  yaxis=dict(
    title='BPM',
    range=[0, 260]
  ),
  dragmode='pan', # Set pan as default dragmode
  uirevision='constant', # Preserve zoom on redraw
)

# Show figure
fig.show()

# Plot smart BPM over time=====================================================================================================
# Find the index of the maximum BPM value
max_bpm_index = np.argmax(smart_bpm_values)
max_bpm_time = time_windows[max_bpm_index]
max_bpm = smart_bpm_values[max_bpm_index]

# Find the index of the minimum BPM value
min_bpm_index = np.argmin(smart_bpm_values)
min_bpm_time = time_windows[min_bpm_index]
min_bpm = smart_bpm_values[min_bpm_index]

avg_bpm = np.mean(smart_bpm_values)

# Shift the x-axis since window_length time needs to pass before data is valid
shifted_time_windows = np.array(time_windows) + window_length - 4 # further adjust

fig, ax1 = plt.subplots(figsize=(15, 6))
ax1.plot(shifted_time_windows, smart_bpm_values, marker='o', linestyle='-', color='#47a5c4', markersize=2.5, markerfacecolor='#4a4a4a')

# Create a second x-axis
ax2 = ax1.twiny()

# Calculate the labels and positions for the new x-axis
axis_interval = 10  # can adjust graph axis display, in seconds
xticks_positions = range(0, int(max(time_windows)), axis_interval)
xticks_labels = [
    f"{int(tick//60)}:{int(tick%60)//10}" for tick in xticks_positions
]

# Apply the new x-axis labels and positions to the second axis
ax2.set_xticks(xticks_positions)
ax2.set_xticklabels(xticks_labels, fontsize=8)

# Set the x-axis limits for ax2
ax2.set_xlim(ax1.get_xlim())  # This line ensures ax2 starts and ends at the same points as ax1

# Label both axes
ax1.set_xlabel('Time (s)')
ax2.set_xlabel('Time (min:sec)')
ax1.set_ylabel('BPM')

# Add annotations for max, min, and average BPM
ax1.annotate(f'{max_bpm:.1f}', xy=(max_bpm_time, max_bpm), textcoords="offset points", xytext=(0,10), ha='center', color='#e36f6f')
ax1.annotate(f'{min_bpm:.1f}', xy=(min_bpm_time, min_bpm), textcoords="offset points", xytext=(0,10), ha='center', color='#a3d194')

ax1.annotate(f'Avg BPM: {avg_bpm:.1f}', xy=(1.1,1), xycoords='axes fraction', fontsize=10, ha='right', va='top')

# Set y-axis limits when rest view
if not (np.isnan(min_bpm) or np.isnan(max_bpm) or np.isinf(min_bpm) or np.isinf(max_bpm)):
    ax1.set_ylim([min_bpm - 10, max_bpm + 10])  # Adjust the +/- 10 as needed
else:
    print("Warning: Cannot set Y-axis limits due to invalid min or max BPM.")

file_name = ''.join(char if ord(char) < 128 else 'â–¡' for char in file_name) #replaces non-ASCII characters for matplotlib
plt.title(f'BPM Over Time - File: {file_name}')
plt.grid(True)
plt.show()

